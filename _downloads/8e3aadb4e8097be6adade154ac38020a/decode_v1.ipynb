{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Recontruct a 2D visual stimulus from real fMRI data\nBla.\nHere we decode a 2D stimulus from te Szinte (2024)-dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import HTML\nimport seaborn as sns\nfrom braincoder.utils.data import load_szinte2024\nimport numpy as np\nimport pandas as pd\n\n# Load data (high-res for PRF fitting)\ndata = load_szinte2024()\nstimulus = data['stimulus']\ngrid_coordinates = data['grid_coordinates']\ntr = data['tr']\ndata = data['v1_timeseries']\n\nfrom braincoder.models import GaussianPRF2DWithHRF\nfrom braincoder.hrf import SPMHRFModel\n\nmodel = GaussianPRF2DWithHRF(grid_coordinates=grid_coordinates, \n                      paradigm=stimulus,\n                    hrf_model=SPMHRFModel(tr=tr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "\"\"\"\nFit parameters\n--------------\n\"\"\"\n# Fit PRF parameters (encoding model)\nfrom braincoder.optimize import ParameterFitter\n\n# We set up a parameter fitter\npar_fitter = ParameterFitter(model, data, stimulus)\n\n# We set up a grid of parameters to search over\nx = np.linspace(-8, 8, 20)\ny = np.linspace(-4, 4, 20)\nsd = np.linspace(1, 5, 10)\n\n# For now, we only use one amplitude and baseline, because we\n# use a correlation cost function, which is indifferent to\n# the overall scaling of the model\n# We can easily estimate these later using OLS\namplitudes = [1.0]\nbaseline = [0.0]\n\n# Note that the grids should be given in the correct order (can be found back in\n# model.parameter_labels)\ngrid_pars = par_fitter.fit_grid(x, y, sd, baseline, amplitudes, use_correlation_cost=True)\n\n# Once we have the best parameters from the grid, we can optimize the baseline\n# and amplitude\nrefined_grid_pars = par_fitter.refine_baseline_and_amplitude(grid_pars)\n\n# Now we use gradient descent to further optimize the parameters\npars = par_fitter.fit(init_pars=refined_grid_pars, learning_rate=1e-2, max_n_iterations=5000,\n        min_n_iterations=100,\n        r2_atol=0.0001)\n\nfrom braincoder.utils import get_rsq\nfitted_r2 = get_rsq(data, model.predict(parameters=pars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "\"\"\"\nAnalyze PRF locations\n---------------------\n\"\"\"\n# Let's plot the location of all these PRFs:\nsns.relplot(x='x', y='y', hue='r2', data=pars.join(fitted_r2.to_frame('r2')), size='sd', sizes=(10, 100), palette='viridis')\nplt.title('PRF locations')\n\n# Now we get the 250 best voxels:\nbest_voxels = fitted_r2.sort_values(ascending=False).iloc[:250].index\n\nplt.figure()\nsns.relplot(x='x', y='y', hue='r2', data=pars.loc[best_voxels].join(fitted_r2.to_frame('r2')), size='sd', sizes=(10, 100), palette='viridis')\nplt.title('PRF locations (best 250 voxels)')\n\n\"\"\"\nFit noise model on residuals\n----------------------------\n\"\"\"\nfrom braincoder.optimize import ResidualFitter\nresid_fitter = ResidualFitter(model, data.loc[:, best_voxels], stimulus, parameters=pars.loc[best_voxels])\nomega, dof = resid_fitter.fit()\n\n\"\"\"\nReconstruct stimulus\n--------------------\n\nFor stimulus reconstruction, we slightly downsample the stimulus space\notherwise the optimization takes too long on a CPU\nwe can do that by simply setting up a new model with a different grid\n\n\"\"\"\ndata = load_szinte2024(resize_factor=2.5)\ngrid_coordinates = data['grid_coordinates']\nstimulus = data['stimulus']\ntr = data['tr']\ndata = data['v1_timeseries']\n\nmodel = GaussianPRF2DWithHRF(grid_coordinates=grid_coordinates, \n                     parameters=pars.loc[best_voxels],\n                    hrf_model=SPMHRFModel(tr=tr))\n\n# We set up a stimulus fitter\nfrom braincoder.optimize import StimulusFitter\nstim_fitter = StimulusFitter(data.loc[:, best_voxels], model, omega)\n\n# Legacy Adam is a bit faster than the default Adam optimizer on M1\n# Learning rate of 1.0 is a bit high, but works well here\nreconstructed_stimulus = stim_fitter.fit(legacy_adam=True, min_n_iterations=200, max_n_iterations=500, learning_rate=.1)\n\ndef play_reconstruction(reconstructed_stimulus):\n\n  # Here we make a movie of the decoded stimulus\n  # Set up a function to draw a single frame\n  vmin, vmax = 0.0, np.quantile(reconstructed_stimulus.values.ravel(), 0.99)\n\n  def update(frame):\n      plt.clf()  # Clear the current figure\n      plt.imshow(reconstructed_stimulus.stack('y').loc[frame], cmap='viridis', vmin=vmin, vmax=vmax)\n      plt.axis('off')\n      plt.title(f\"Frame {frame}\")\n\n  # Create the animation\n  fig = plt.figure()\n  ani = FuncAnimation(fig, update, frames=range(stimulus.shape[0]), interval=100)\n\n  return HTML(ani.to_html5_video())\n\nplay_reconstruction(reconstructed_stimulus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "\"\"\"\nReconstruct stimulus with L2-norm\n---------------------------------\nNote how this reconstructed stimulus is very sparse and doesn't look a lot like\nthe actual image. Part of the problem is that\nthe optimisation is very unconstrained: we have 250 voxels times \n150 (correlated!) datapoints, but ~800 time 150 stimulus pixels\nWe can induce less extreme intensities, and thereby less \nsparseness, by inducing a L2-penalty on the stimulus intensities\n\"\"\"\n\nreconstructed_stimulus = stim_fitter.fit(legacy_adam=True, min_n_iterations=200, max_n_iterations=1000, learning_rate=0.1, l2_norm=0.01)\n\nplay_reconstruction(reconstructed_stimulus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "\"\"\"\nReconstruct stimulus with L1-norm\n---------------------------------\nFor completeness, one can also use a sparse-inducing L1-norm\n\"\"\"\nreconstructed_stimulus = stim_fitter.fit(legacy_adam=True, min_n_iterations=200, max_n_iterations=1000, learning_rate=.1, l1_norm=0.01)\nplay_reconstruction(reconstructed_stimulus)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}