{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Fit a 2D PRF model\n\nHere we fit a 2D PRF model to data from the Szinte (2024)-dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nfrom matplotlib.animation import FuncAnimation\nfrom IPython.display import HTML, display\n\nfrom braincoder.utils.data import load_szinte2024\nimport numpy as np\nimport pandas as pd\n\n# Load data\ndata = load_szinte2024()\nstimulus = data['stimulus']\ngrid_coordinates = data['grid_coordinates']\n\n# Set up a function to draw a single frame\ndef update(frame):\n    plt.clf()  # Clear the current figure\n    plt.imshow(stimulus[frame, :, :].T, cmap='viridis')\n    plt.title(f\"Frame {frame}\")\n\n# Create the animation\nfig = plt.figure()\nani = FuncAnimation(fig, update, frames=range(stimulus.shape[0]), interval=100)\n\n# Convert to HTML for easy display\nHTML(ani.to_html5_video())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set up a PRF model\n# Now we will set up fake PRFs just to show how the data is structured\n# We make a 9-by-9 grid of simulated PRFs\nx, y = np.meshgrid(np.linspace(-6, 6, 3), np.linspace(-4, 4, 3))\n\n# Set them up in a parameter table\n# All PRFs have the same baseline and amplitude\nfrom braincoder.models import GaussianPRF2DWithHRF\nfrom braincoder.hrf import SPMHRFModel\n\nparameters = pd.DataFrame({'x':x.ravel(),\n               'y':y.ravel(),\n               'sd':2.5,\n               'baseline':0.0,\n               'amplitude':1.}).astype(np.float32)\nmodel = GaussianPRF2DWithHRF(grid_coordinates=grid_coordinates, \n                      paradigm=stimulus,\n                     parameters=parameters,\n                    hrf_model=SPMHRFModel(tr=data['tr']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Let's plot all the RFs\nrfs = model.get_rf(as_frame=True)\n\nfor i, rf in rfs.groupby(level=0):\n    plt.subplot(3, 3, i+1)\n    plt.title(f'RF {i+1}')\n    plt.imshow(rf.unstack('y').loc[i].T)\n    plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We simulate data for the given paradigm and parameters and plot the resulting time series\nimport seaborn as sns\ndata = model.simulate(noise=1.)\ndata.columns.set_names('voxel', inplace=True)\ntmp = data.stack().to_frame('activity')\nsns.relplot(x='frame', y='activity', data=tmp.reset_index(), hue='voxel', kind='line', palette=sns.color_palette('tab10', n_colors=parameters.shape[0]), aspect=2.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# We can also fit parameters back to data\nfrom braincoder.optimize import ParameterFitter\n\n# We set up a parameter fitter\npar_fitter = ParameterFitter(model, data, stimulus)\n\n# We set up a grid of parameters to search over\nx = np.linspace(-8, 8, 20)\ny = np.linspace(-4, 4, 20)\nsd = np.linspace(1, 5, 10)\n\n# For now, we only use one amplitude and baseline, because we\n# use a correlation cost function, which is indifferent to\n# the overall scaling of the model\n# We can easily estimate these later using OLS\namplitudes = [1.0]\nbaseline = [0.0]\n\n# Note that the grids should be given in the correct order (can be found back in\n# model.parameter_labels)\ngrid_pars = par_fitter.fit_grid(x, y, sd, baseline, amplitudes, use_correlation_cost=True)\n\n# Once we have the best parameters from the grid, we can optimize the baseline\n# and amplitude\nrefined_grid_pars = par_fitter.refine_baseline_and_amplitude(grid_pars)\n\n# We get the explained variance of these parameters\nfrom braincoder.utils import get_rsq\nrefined_grid_r2 = get_rsq(data, model.predict(parameters=refined_grid_pars))\n\n# Now we use gradient descent to further optimize the parameters\npars = par_fitter.fit(init_pars=refined_grid_pars, learning_rate=1e-2, max_n_iterations=5000,\n        min_n_iterations=100,\n        r2_atol=0.0001)\n\nfitted_r2 = get_rsq(data, model.predict(parameters=pars))\n\n# The fitted R2s tend to be a bit better than the grid R2s\ndisplay(refined_grid_r2.to_frame('r2').join(fitted_r2.to_frame('r2'), lsuffix='_grid', rsuffix='_fitted'))\n\n# The real parameters are very similar to the estimated parameters\ndisplay(pars.join(parameters, lsuffix='_fit', rsuffix='_true'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Decode the *stimulus* from \"unseen\" data:\n# First we need to fit a noise model\nfrom braincoder.optimize import ResidualFitter\nresid_fitter = ResidualFitter(model, data, stimulus, parameters=pars)\nomega, dof = resid_fitter.fit()\n\n# Simulate new \"unseen\" data\nunseen_data = model.simulate(noise=1.)\n\n# For stimulus reconstruction, we slightly downsample the stimulus space\n# otherwise the optimization takes too long on a CPU\n# we can do that by simply setting up a new model with a different grid\ndata = load_szinte2024(resize_factor=2.5)\ngrid_coordinates = data['grid_coordinates']\nstimulus = data['stimulus']\n\nmodel = GaussianPRF2DWithHRF(grid_coordinates=grid_coordinates, \n                     parameters=parameters,\n                    hrf_model=SPMHRFModel(tr=data['tr']))\n\n# We set up a stimulus fitter\nfrom braincoder.optimize import StimulusFitter\nstim_fitter = StimulusFitter(unseen_data, model, omega)\n\n# Legacy Adam is a bit faster than the default Adam optimizer on M1\n# Learning rate of 1.0 is a bit high, but works well here\nreconstructed_stimulus = stim_fitter.fit(legacy_adam=True, min_n_iterations=200, max_n_iterations=200, learning_rate=.1)\n\n# Here we make a movie of the decoded stimulus\n# Set up a function to draw a single frame\nvmin, vmax = 0.0, np.quantile(reconstructed_stimulus.values.ravel(), 0.95)\n\ndef update(frame):\n    plt.clf()  # Clear the current figure\n    plt.imshow(reconstructed_stimulus.stack('y').loc[frame], cmap='viridis', vmin=vmin, vmax=vmax)\n    plt.axis('off')\n    plt.title(f\"Frame {frame}\")\n\n# Create the animation\nfig = plt.figure()\nani = FuncAnimation(fig, update, frames=range(stimulus.shape[0]), interval=100)\n\nHTML(ani.to_html5_video())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}