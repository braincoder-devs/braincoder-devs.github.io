{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Decoding 2D stimuli from neural data\n\nHere, we are decoding oriented stimuli from neural\ndata that have an extra dimension: amplitude.\n\nAmplitude can be interpreted as the stimulus drive\nand has been shown to be modulated by cognitive effects\nsuch as expectation and attention.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Set up a neural model\nfrom braincoder.models import VonMisesPRF\nimport numpy as np\nimport pandas as pd\nimport scipy.stats as ss\nnoise = 0.5\n\n# We are setting up a VonMisesPRF model with 8 orientations,\n# We have 8 voxels, each with a linear combination of the 8 von Mises functions\n# We use the identity matrix with some noice, so that each voxel is driven by\n# largely by a single PRF\nparameters = pd.DataFrame({'mu':np.linspace(0, 2*np.pi, 8, False), 'kappa':1.0, 'amplitude':1.0, 'baseline':0.0})\n\nweights = np.identity(8) * 5.0\nweights += np.random.rand(8, 8)\nmodel = VonMisesPRF(parameters=parameters, model_stimulus_amplitude=True, weights=weights)\n\n# Note how the stimulus type is now `OneDimensionalRadialStimulusWithAmplitude`\n# which means that the stimulus is two-dimensional\nprint(model.stimulus)\nprint(model.stimulus.dimension_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Now we can simulate some data and estimate parameters+noise\nmapper_paradigm = pd.DataFrame({'x (radians)':np.random.rand(100)*2*np.pi, 'amplitude':1.})\ndata = model.simulate(paradigm=mapper_paradigm, noise=noise)\n\n# Set up parameter fitter\nfrom braincoder.optimize import WeightFitter, ResidualFitter\nfitter = WeightFitter(model, parameters, data, mapper_paradigm)\n# With 8 overlapping Von Mises functions, we already need some regularisation, hence alpha=1.0\nfitted_weights = fitter.fit(alpha=1.0)\n\n# Now we fit the covariance matrix on the residuals\nresid_fitter = ResidualFitter(model, data, mapper_paradigm, parameters, fitted_weights)\nomega, dof = resid_fitter.fit(progressbar=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Now we set up an experimental paradigm with two conditions\n# An `attended` and an `unattended` condition.\n# In the attended condition, the stimulus will have more drive (1.5),\n# in the unattended condition, the stimulus will have less drive (0.5).\n\nn = 200\nexperimental_paradigm = pd.DataFrame(index=pd.MultiIndex.from_product([np.arange(n/2.), ['attended', 'unattended']], names=['frame', 'condition']))\n\n# Random orientations\nexperimental_paradigm['x (radians)'] = np.random.rand(n)*2*np.pi\n\n# Amplitudes have some noise\nexperimental_paradigm['amplitude'] = np.where(experimental_paradigm.index.get_level_values('condition') == 'attended', ss.norm(1.5, 0.1).rvs(n), ss.norm(.5, 0.1).rvs(n))\nexperimental_data = model.simulate(paradigm=experimental_paradigm, noise=noise)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot the data\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ntmp = experimental_data.set_index(experimental_paradigm['x (radians)'], append=True).stack().to_frame('activity')\ng = sns.FacetGrid(tmp.reset_index(), col='unit', col_wrap=4, hue='condition', palette='coolwarm_r')\ng.map(plt.scatter, 'x (radians)', 'activity', alpha=0.85)\ng.add_legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Now we can calculate the 2D likelihood/posterior of different orientations+amplitudes for the data\nlower_amplitude, higher_amplitude = 0.0, 4.5\npotential_amplitudes = np.linspace(lower_amplitude, higher_amplitude, 50)\npotential_orientations = np.linspace(0, 2*np.pi, 50, False)\n\n# Make sure ground truth is the potential stimuli\npotential_amplitudes = np.sort(np.append(potential_amplitudes, [0.5, 1.5]))\n\n# We use the `pd.MultiIndex.from_product` function to create a grid of possible stimuli\npotential_stimuli = pd.MultiIndex.from_product([potential_orientations, potential_amplitudes], names=['x (radians)', 'amplitude']).to_frame(index=False)\n\n# Now we get, for each data point, the likelihood of each possible stimulus\nll = model.get_stimulus_pdf(experimental_data, potential_stimuli)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot 2D posteriors for first 9 trials\n\n# Once we have these 2D likelihoods, now we want to be able to plot them.\ndef plot_trial(key, ll=ll, paradigm=experimental_paradigm, xlabel=False, ylabel=False):\n    # We use the `stack` method to turn the `amplitude` dimension into a column\n    ll = ll.loc[key].unstack('amplitude')\n    \n    # Use imshow to show a 2D image of the likelihood\n    vmin, vmax = ll.min().min(), ll.max().max()\n    plt.imshow(ll, origin='lower', aspect='auto', extent=[lower_amplitude, higher_amplitude, 0, 2*np.pi], vmin=vmin, vmax=vmax)\n\n    # Plot the _actual_ ground truth amplitude and orientation\n    plt.scatter(paradigm.loc[key]['amplitude'], paradigm.loc[key]['x (radians)'], c='r', s=25, marker='+')\n\n    # Some housekeeping for the subplots\n    plt.title(f'Trial {key[0]}')\n    if xlabel:\n        plt.xticks()\n        plt.xlabel('Amplitude')\n    else:\n        plt.xticks([])\n\n    if ylabel:\n        plt.yticks()\n        plt.ylabel('Orientation')\n    else:\n        plt.yticks([])\n\ndef plot_condition(condition):\n    \"\"\"\n    Plot the 2D posterior for a given condition for the first 9 trials.\n\n    Parameters:\n    condition (str): The condition for which to plot the posterior.\n\n    Returns:\n    None\n    \"\"\"\n    plt.figure(figsize=(7, 7))\n    for ix in range(9):\n        plt.subplot(3, 3, ix+1)\n\n        xlabel = ix in [6, 7, 8]\n        ylabel = ix in [0, 3, 6]\n\n        plot_trial((ix, condition), xlabel=xlabel, ylabel=ylabel)\n\n    plt.suptitle(f'2D posterior ({condition} trials)')\n    plt.tight_layout()\n\nplot_condition('attended')\nplot_condition('unattended')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Now we can calculate the 1D posterior for specific orientations _or_ amplitudes\n\n# Marginalize out orientations\namplitudes_posterior = ll.groupby('amplitude', axis=1).sum()\namplitudes_posterior = amplitudes_posterior.div(np.trapz(amplitudes_posterior, amplitudes_posterior.columns, axis=1), axis=0) # This is the same as normalizing the posterior\n\n# Marginalize out amplitudes\norientations_posterior = ll.groupby('x (radians)', axis=1).sum()\norientations_posterior = orientations_posterior.div(np.trapz(orientations_posterior, orientations_posterior.columns, axis=1), axis=0)\n\n# Plot orientation posteriors\ntmp = orientations_posterior.stack().loc[:8].to_frame('p')\n\ng = sns.FacetGrid(tmp.reset_index(), col='frame', col_wrap=3, hue='condition', palette='coolwarm_r')\ng.map(plt.plot, 'x (radians)', 'p', alpha=0.85)\n\ng.map(plt.axvline, x=1.5, c=sns.color_palette('coolwarm_r', 2)[0], ls='--')\ng.map(plt.axvline, x=0.5, c=sns.color_palette('coolwarm_r', 2)[1], ls='--')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Use the ground truth amplitude to improve the orientation posterior\n# so p(orientation|true_amplitude)\nconditional_orientation_ll = pd.concat((ll.stack().xs('attended', 0, 'condition').xs(1.5, 0, 'amplitude'),\n                                        ll.stack().xs('unattended', 0, 'condition').xs(0.5, 0, 'amplitude')),\n                                        axis=0,\n                                        keys=['attended', 'unattended'],\n                                        names=['condition']).swaplevel(0, 1).sort_index()\n\n# Normalize!\nconditional_orientation_ll = conditional_orientation_ll.div(np.trapz(conditional_orientation_ll, conditional_orientation_ll.columns, axis=1), axis=0)\ntmp = conditional_orientation_ll.stack().loc[:8].to_frame('p')\n\ng = sns.FacetGrid(tmp.reset_index(), col='frame', col_wrap=3, hue='condition', palette='coolwarm_r')\ng.map(plt.plot, 'x (radians)', 'p', alpha=0.85)\n\ng.map(plt.axvline, x=1.5, c=sns.color_palette('coolwarm_r', 2)[0], ls='--')\ng.map(plt.axvline, x=0.5, c=sns.color_palette('coolwarm_r', 2)[1], ls='--')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Intro to complex numbers\n\ndef to_complex(x):\n    return np.exp(1j*x)\n\ndef from_complex(x):\n    x = np.angle(x)\n    return np.where(x < 0, x + 2*np.pi, x)\n\n# Let's plot the firs 10 trials in the complex plane\nfirst_10_trials = experimental_paradigm.xs('attended', 0, 'condition')['x (radians)'].iloc[:10]\n\norientations_complex = to_complex(first_10_trials.values)\n\nplt.figure()\nplt.scatter(orientations_complex.real, orientations_complex.imag, c=first_10_trials.index)\nplt.gca().set_aspect('equal')\nplt.xlabel('Real')\nplt.ylabel('Imaginary')\nsns.despine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Get posterior means by integrating over complex numbers\ndef wrap_angle(x):\n    return np.mod(x + np.pi, 2*np.pi) - np.pi\n\ndef get_posterior_stats(posterior, ground_truth=None):\n    posterior = posterior.copy()\n    complex_grid = np.asarray(to_complex(posterior.columns))\n\n    # Take integral over the posterior to get to the expectation (mean posterior)\n    # In this case a complex number that we convert back to an angle between 0 and 2pi\n    E = from_complex(np.trapz(posterior*complex_grid[np.newaxis,:], axis=1))\n    \n    # Take the integral over the posterior to get the expectation of the distance to the \n    # mean posterior (i.e., standard deviation)\n    relative_error = E[:, np.newaxis] - posterior.columns.values[np.newaxis,:]\n\n    # Wrap the angle to be between 0 and pi, the error can never be larger than pi (180 degrees)\n    relative_error = wrap_angle(relative_error)\n    absolute_error = np.abs(relative_error)\n    sd = np.trapz(absolute_error * posterior, posterior.columns, axis=1)\n\n    stats = pd.DataFrame({'E':E, 'sd':sd}, index=posterior.index)\n\n    if ground_truth is not None:\n        stats['E_error'] = wrap_angle(stats['E'] - ground_truth)\n        stats['E_error_abs'] = np.abs(stats['E_error'])\n        stats['ground_truth'] = ground_truth\n\n    return stats\n\nposterior_stats = get_posterior_stats(conditional_orientation_ll, ground_truth=experimental_paradigm['x (radians)'].values)\n\n# Circular correlations:\nimport pingouin as pg\nposterior_stats.groupby('condition').apply(lambda d: pd.Series(pg.circ_corrcc(d['E'], d['ground_truth']), index=['rho', 'p']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Let's see how far the posterior mean is from the ground truth\n# by plotting the estimates and groun truth in the complex plane\npalette = sns.color_palette('coolwarm_r', 2)\n\n# Create custom legend\nlegend_elements = [\n    plt.Line2D([0], [0], marker='x', color='k', label='Estimate', markersize=8, linewidth=0),\n    plt.Line2D([0], [0], marker='o', color='k', label='Truth', markersize=8, linewidth=0),\n    plt.Line2D([0], [0], marker='s', color=palette[0], label='Attended', markersize=8, linewidth=0),\n    plt.Line2D([0], [0], marker='s', color=palette[1], label='Unattended', markersize=8, linewidth=0)\n]\n\n# Plot the data\nfor ix, row in posterior_stats.iloc[:10].iterrows():\n    hue = sns.color_palette('coolwarm_r', 2)[['attended', 'unattended'].index(ix[1])]\n\n    estimate_complex = to_complex(row['E'])\n    ground_truth_complex = to_complex(row['ground_truth'])\n    \n    plt.plot([estimate_complex.real, ground_truth_complex.real], [estimate_complex.imag, ground_truth_complex.imag], color=hue)\n    plt.scatter(estimate_complex.real, estimate_complex.imag, color=hue, s=50, marker='x')\n    plt.scatter(ground_truth_complex.real, ground_truth_complex.imag, color=hue, s=50, marker='o')\n\n# Set aspect ratio and remove spines\nplt.gca().set_aspect('equal')\nsns.despine()\n\n# Add legend\nplt.legend(handles=legend_elements)\n\n# Show the plot\nplt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Plot the error as a function of the standard deviation of the posterior\nsns.lmplot(x='sd', y='E_error_abs', data=posterior_stats.reset_index(), hue='condition')\n\n# %%"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}